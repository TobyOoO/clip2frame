<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Layers &mdash; clip2frame 0.1.0 documentation</title>
    
    <link rel="stylesheet" href="../_static/classic.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.1.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="clip2frame 0.1.0 documentation" href="../index.html" />
    <link rel="prev" title="data/" href="../misc/data.html" /> 
  </head>
  <body role="document">
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../misc/data.html" title="data/"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">clip2frame 0.1.0 documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="module-clip2frame.layers">
<span id="layers"></span><h1>Layers<a class="headerlink" href="#module-clip2frame.layers" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="clip2frame.layers.Conv2DXLayer">
<em class="property">class </em><code class="descclassname">clip2frame.layers.</code><code class="descname">Conv2DXLayer</code><span class="sig-paren">(</span><em>incoming</em>, <em>num_filters</em>, <em>filter_size</em>, <em>stride=(1</em>, <em>1)</em>, <em>pad=0</em>, <em>untie_biases=False</em>, <em>W=lasagne.init.GlorotUniform()</em>, <em>b=lasagne.init.Constant(0.)</em>, <em>nonlinearity=lasagne.nonlinearities.rectify</em>, <em>convolution=theano.tensor.nnet.conv2d</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/clip2frame/layers.html#Conv2DXLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#clip2frame.layers.Conv2DXLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>2D convolutional layer</p>
<p>Performs a 2D convolution on its input and optionally adds a bias and
applies an elementwise nonlinearity.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>incoming</strong> : a <code class="xref py py-class docutils literal"><span class="pre">Layer</span></code> instance or a tuple</p>
<blockquote>
<div><p>The layer feeding into this layer, or the expected input shape. The
output of this layer should be a 4D tensor, with shape
<code class="docutils literal"><span class="pre">(batch_size,</span> <span class="pre">num_input_channels,</span> <span class="pre">input_rows,</span> <span class="pre">input_columns)</span></code>.</p>
</div></blockquote>
<p><strong>num_filters</strong> : int</p>
<blockquote>
<div><p>The number of learnable convolutional filters this layer has.</p>
</div></blockquote>
<p><strong>filter_size</strong> : int or iterable of int</p>
<blockquote>
<div><p>An integer or a 2-element tuple specifying the size of the filters.</p>
</div></blockquote>
<p><strong>stride</strong> : int or iterable of int</p>
<blockquote>
<div><p>An integer or a 2-element tuple specifying the stride of the
convolution operation.</p>
</div></blockquote>
<p><strong>pad</strong> : int, iterable of int, &#8216;full&#8217;, &#8216;same&#8217; or &#8216;valid&#8217; (default: 0)</p>
<blockquote>
<div><p>By default, the convolution is only computed where the input and the
filter fully overlap (a valid convolution). When <code class="docutils literal"><span class="pre">stride=1</span></code>, this
yields an output that is smaller than the input by <code class="docutils literal"><span class="pre">filter_size</span> <span class="pre">-</span> <span class="pre">1</span></code>.
The <cite>pad</cite> argument allows you to implicitly pad the input with zeros,
extending the output size.</p>
<p>A single integer results in symmetric zero-padding of the given size on
all borders, a tuple of two integers allows different symmetric padding
per dimension.</p>
<p><code class="docutils literal"><span class="pre">'full'</span></code> pads with one less than the filter size on both sides. This
is equivalent to computing the convolution wherever the input and the
filter overlap by at least one position.</p>
<p><code class="docutils literal"><span class="pre">'same'</span></code> pads with half the filter size (rounded down) on both sides.
When <code class="docutils literal"><span class="pre">stride=1</span></code> this results in an output size equal to the input
size. Even filter size is not supported.</p>
<p><code class="docutils literal"><span class="pre">'strictsamex'</span></code> pads to the right of the third axis (x axis)
to keep the same dim as input
require stride=(1, 1)</p>
<p><code class="docutils literal"><span class="pre">'valid'</span></code> is an alias for <code class="docutils literal"><span class="pre">0</span></code> (no padding / a valid convolution).</p>
<p>Note that <code class="docutils literal"><span class="pre">'full'</span></code> and <code class="docutils literal"><span class="pre">'same'</span></code> can be faster than equivalent
integer values due to optimizations by Theano.</p>
</div></blockquote>
<p><strong>untie_biases</strong> : bool (default: False)</p>
<blockquote>
<div><p>If <code class="docutils literal"><span class="pre">False</span></code>, the layer will have a bias parameter for each channel,
which is shared across all positions in this channel. As a result, the
<cite>b</cite> attribute will be a vector (1D).</p>
<p>If True, the layer will have separate bias parameters for each
position in each channel. As a result, the <cite>b</cite> attribute will be a
3D tensor.</p>
</div></blockquote>
<p><strong>W</strong> : Theano shared variable, expression, numpy array or callable</p>
<blockquote>
<div><p>Initial value, expression or initializer for the weights.
These should be a 4D tensor with shape
<code class="docutils literal"><span class="pre">(num_filters,</span> <span class="pre">num_input_channels,</span> <span class="pre">filter_rows,</span> <span class="pre">filter_columns)</span></code>.
See <code class="xref py py-func docutils literal"><span class="pre">lasagne.utils.create_param()</span></code> for more information.</p>
</div></blockquote>
<p><strong>b</strong> : Theano shared variable, expression, numpy array, callable or <code class="docutils literal"><span class="pre">None</span></code></p>
<blockquote>
<div><p>Initial value, expression or initializer for the biases. If set to
<code class="docutils literal"><span class="pre">None</span></code>, the layer will have no biases. Otherwise, biases should be
a 1D array with shape <code class="docutils literal"><span class="pre">(num_filters,)</span></code> if <cite>untied_biases</cite> is set to
<code class="docutils literal"><span class="pre">False</span></code>. If it is set to <code class="docutils literal"><span class="pre">True</span></code>, its shape should be
<code class="docutils literal"><span class="pre">(num_filters,</span> <span class="pre">output_rows,</span> <span class="pre">output_columns)</span></code> instead.
See <code class="xref py py-func docutils literal"><span class="pre">lasagne.utils.create_param()</span></code> for more information.</p>
</div></blockquote>
<p><strong>nonlinearity</strong> : callable or None</p>
<blockquote>
<div><p>The nonlinearity that is applied to the layer activations. If None
is provided, the layer will be linear.</p>
</div></blockquote>
<p><strong>convolution</strong> : callable</p>
<blockquote>
<div><p>The convolution implementation to use. Usually it should be fine to
leave this at the default value.</p>
</div></blockquote>
<p><strong>**kwargs</strong></p>
<blockquote class="last">
<div><p>Any additional keyword arguments are passed to the <cite>Layer</cite> superclass.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>Theano&#8217;s underlying convolution (<code class="xref py py-func docutils literal"><span class="pre">theano.tensor.nnet.conv.conv2d()</span></code>)
only supports <code class="docutils literal"><span class="pre">pad=0</span></code> and <code class="docutils literal"><span class="pre">pad='full'</span></code>. This layer emulates other modes
by cropping a full convolution or explicitly padding the input with zeros.</p>
<p class="rubric">Attributes</p>
<table border="1" class="docutils">
<colgroup>
<col width="3%" />
<col width="97%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>W</td>
<td>(Theano shared variable or expression) Variable or expression representing the filter weights.</td>
</tr>
<tr class="row-even"><td>b</td>
<td>(Theano shared variable or expression) Variable or expression representing the biases.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="clip2frame.layers.Conv2DXLayer.get_W_shape">
<code class="descname">get_W_shape</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/clip2frame/layers.html#Conv2DXLayer.get_W_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#clip2frame.layers.Conv2DXLayer.get_W_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shape of the weight matrix <cite>W</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">tuple of int</p>
<blockquote class="last">
<div><p>The shape of the weight matrix.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="clip2frame.layers.FixedGaussianScan1DLayer">
<em class="property">class </em><code class="descclassname">clip2frame.layers.</code><code class="descname">FixedGaussianScan1DLayer</code><span class="sig-paren">(</span><em>incoming</em>, <em>filter_size</em>, <em>init_std</em>, <em>stride=1</em>, <em>pad=0</em>, <em>untie_biases=False</em>, <em>W=lasagne.init.GlorotUniform()</em>, <em>b=lasagne.init.Constant(0.)</em>, <em>nonlinearity=lasagne.nonlinearities.rectify</em>, <em>convolution=lasagne.theano_extensions.conv.conv1d_mc0</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/clip2frame/layers.html#FixedGaussianScan1DLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#clip2frame.layers.FixedGaussianScan1DLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>1D convolutional layer
Gaussian filter is not changing during the training</p>
<p>Performs a 1D convolution on its input and optionally adds a bias and
applies an elementwise nonlinearity.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>incoming</strong> : a <code class="xref py py-class docutils literal"><span class="pre">Layer</span></code> instance or a tuple</p>
<blockquote>
<div><p>The layer feeding into this layer, or the expected input shape. The
output of this layer should be a 3D tensor, with shape
<code class="docutils literal"><span class="pre">(batch_size,</span> <span class="pre">num_input_channels,</span> <span class="pre">input_length)</span></code>.</p>
</div></blockquote>
<p><strong>num_filters</strong> : int</p>
<blockquote>
<div><p>The number of learnable convolutional filters this layer has.</p>
</div></blockquote>
<p><strong>filter_size</strong> : int or iterable of int</p>
<blockquote>
<div><p>An integer or a 1-element tuple specifying the size of the filters.</p>
</div></blockquote>
<p><strong>stride</strong> : int or iterable of int</p>
<blockquote>
<div><p>An integer or a 1-element tuple specifying the stride of the
convolution operation.</p>
</div></blockquote>
<p><strong>pad</strong> : int, iterable of int, &#8216;full&#8217;, &#8216;same&#8217; or &#8216;valid&#8217; (default: 0)</p>
<blockquote>
<div><p>By default, the convolution is only computed where the input and the
filter fully overlap (a valid convolution). When <code class="docutils literal"><span class="pre">stride=1</span></code>, this
yields an output that is smaller than the input by <code class="docutils literal"><span class="pre">filter_size</span> <span class="pre">-</span> <span class="pre">1</span></code>.
The <cite>pad</cite> argument allows you to implicitly pad the input with zeros,
extending the output size.</p>
<p>An integer or a 1-element tuple results in symmetric zero-padding of
the given size on both borders.</p>
<p><code class="docutils literal"><span class="pre">'full'</span></code> pads with one less than the filter size on both sides. This
is equivalent to computing the convolution wherever the input and the
filter overlap by at least one position.</p>
<p><code class="docutils literal"><span class="pre">'same'</span></code> pads with half the filter size (rounded down) on both sides.
When <code class="docutils literal"><span class="pre">stride=1</span></code> this results in an output size equal to the input
size. Even filter size is not supported.</p>
<p><code class="docutils literal"><span class="pre">'valid'</span></code> is an alias for <code class="docutils literal"><span class="pre">0</span></code> (no padding / a valid convolution).</p>
</div></blockquote>
<p><strong>untie_biases</strong> : bool (default: False)</p>
<blockquote>
<div><p>If <code class="docutils literal"><span class="pre">False</span></code>, the layer will have a bias parameter for each channel,
which is shared across all positions in this channel. As a result, the
<cite>b</cite> attribute will be a vector (1D).</p>
<p>If True, the layer will have separate bias parameters for each
position in each channel. As a result, the <cite>b</cite> attribute will be a
matrix (2D).</p>
</div></blockquote>
<p><strong>W</strong> : Theano shared variable, expression, numpy array or callable</p>
<blockquote>
<div><p>Initial value, expression or initializer for the weights.
These should be a 3D tensor with shape
<code class="docutils literal"><span class="pre">(num_filters,</span> <span class="pre">num_input_channels,</span> <span class="pre">filter_length)</span></code>.
See <code class="xref py py-func docutils literal"><span class="pre">lasagne.utils.create_param()</span></code> for more information.</p>
</div></blockquote>
<p><strong>b</strong> : Theano shared variable, expression, numpy array, callable or <code class="docutils literal"><span class="pre">None</span></code></p>
<blockquote>
<div><p>Initial value, expression or initializer for the biases. If set to
<code class="docutils literal"><span class="pre">None</span></code>, the layer will have no biases. Otherwise, biases should be
a 1D array with shape <code class="docutils literal"><span class="pre">(num_filters,)</span></code> if <cite>untied_biases</cite> is set to
<code class="docutils literal"><span class="pre">False</span></code>. If it is set to <code class="docutils literal"><span class="pre">True</span></code>, its shape should be
<code class="docutils literal"><span class="pre">(num_filters,</span> <span class="pre">input_length)</span></code> instead.
See <code class="xref py py-func docutils literal"><span class="pre">lasagne.utils.create_param()</span></code> for more information.</p>
</div></blockquote>
<p><strong>nonlinearity</strong> : callable or None</p>
<blockquote>
<div><p>The nonlinearity that is applied to the layer activations. If None
is provided, the layer will be linear.</p>
</div></blockquote>
<p><strong>convolution</strong> : callable</p>
<blockquote>
<div><p>The convolution implementation to use. The
<cite>lasagne.theano_extensions.conv</cite> module provides some alternative
implementations for 1D convolutions, because the Theano API only
features a 2D convolution implementation. Usually it should be fine
to leave this at the default value.</p>
</div></blockquote>
<p><strong>**kwargs</strong></p>
<blockquote class="last">
<div><p>Any additional keyword arguments are passed to the <cite>Layer</cite> superclass.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>Theano&#8217;s underlying convolution (<code class="xref py py-func docutils literal"><span class="pre">theano.tensor.nnet.conv.conv2d()</span></code>)
only supports <code class="docutils literal"><span class="pre">pad=0</span></code> and <code class="docutils literal"><span class="pre">pad='full'</span></code>. This layer emulates other modes
by cropping a full convolution or explicitly padding the input with zeros.</p>
<p class="rubric">Attributes</p>
<table border="1" class="docutils">
<colgroup>
<col width="3%" />
<col width="97%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>W</td>
<td>(Theano shared variable or expression) Variable or expression representing the filter weights.</td>
</tr>
<tr class="row-even"><td>b</td>
<td>(Theano shared variable or expression) Variable or expression representing the biases.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="clip2frame.layers.FixedGaussianScan1DLayer.get_W_shape">
<code class="descname">get_W_shape</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/clip2frame/layers.html#FixedGaussianScan1DLayer.get_W_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#clip2frame.layers.FixedGaussianScan1DLayer.get_W_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shape of the weight matrix <cite>W</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">tuple of int</p>
<blockquote class="last">
<div><p>The shape of the weight matrix.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="clip2frame.layers.GaussianScan1DLayer">
<em class="property">class </em><code class="descclassname">clip2frame.layers.</code><code class="descname">GaussianScan1DLayer</code><span class="sig-paren">(</span><em>incoming</em>, <em>filter_size</em>, <em>init_std</em>, <em>stride=1</em>, <em>pad=0</em>, <em>untie_biases=False</em>, <em>W=lasagne.init.GlorotUniform()</em>, <em>b=lasagne.init.Constant(0.)</em>, <em>nonlinearity=lasagne.nonlinearities.rectify</em>, <em>convolution=lasagne.theano_extensions.conv.conv1d_mc0</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/clip2frame/layers.html#GaussianScan1DLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#clip2frame.layers.GaussianScan1DLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>1D convolutional layer</p>
<p>Performs a 1D convolution on its input and optionally adds a bias and
applies an elementwise nonlinearity.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>incoming</strong> : a <code class="xref py py-class docutils literal"><span class="pre">Layer</span></code> instance or a tuple</p>
<blockquote>
<div><p>The layer feeding into this layer, or the expected input shape. The
output of this layer should be a 3D tensor, with shape
<code class="docutils literal"><span class="pre">(batch_size,</span> <span class="pre">num_input_channels,</span> <span class="pre">input_length)</span></code>.</p>
</div></blockquote>
<p><strong>num_filters</strong> : int</p>
<blockquote>
<div><p>The number of learnable convolutional filters this layer has.</p>
</div></blockquote>
<p><strong>filter_size</strong> : int or iterable of int</p>
<blockquote>
<div><p>An integer or a 1-element tuple specifying the size of the filters.</p>
</div></blockquote>
<p><strong>stride</strong> : int or iterable of int</p>
<blockquote>
<div><p>An integer or a 1-element tuple specifying the stride of the
convolution operation.</p>
</div></blockquote>
<p><strong>pad</strong> : int, iterable of int, &#8216;full&#8217;, &#8216;same&#8217; or &#8216;valid&#8217; (default: 0)</p>
<blockquote>
<div><p>By default, the convolution is only computed where the input and the
filter fully overlap (a valid convolution). When <code class="docutils literal"><span class="pre">stride=1</span></code>, this
yields an output that is smaller than the input by <code class="docutils literal"><span class="pre">filter_size</span> <span class="pre">-</span> <span class="pre">1</span></code>.
The <cite>pad</cite> argument allows you to implicitly pad the input with zeros,
extending the output size.</p>
<p>An integer or a 1-element tuple results in symmetric zero-padding of
the given size on both borders.</p>
<p><code class="docutils literal"><span class="pre">'full'</span></code> pads with one less than the filter size on both sides. This
is equivalent to computing the convolution wherever the input and the
filter overlap by at least one position.</p>
<p><code class="docutils literal"><span class="pre">'same'</span></code> pads with half the filter size (rounded down) on both sides.
When <code class="docutils literal"><span class="pre">stride=1</span></code> this results in an output size equal to the input
size. Even filter size is not supported.</p>
<p><code class="docutils literal"><span class="pre">'valid'</span></code> is an alias for <code class="docutils literal"><span class="pre">0</span></code> (no padding / a valid convolution).</p>
</div></blockquote>
<p><strong>untie_biases</strong> : bool (default: False)</p>
<blockquote>
<div><p>If <code class="docutils literal"><span class="pre">False</span></code>, the layer will have a bias parameter for each channel,
which is shared across all positions in this channel. As a result, the
<cite>b</cite> attribute will be a vector (1D).</p>
<p>If True, the layer will have separate bias parameters for each
position in each channel. As a result, the <cite>b</cite> attribute will be a
matrix (2D).</p>
</div></blockquote>
<p><strong>W</strong> : Theano shared variable, expression, numpy array or callable</p>
<blockquote>
<div><p>Initial value, expression or initializer for the weights.
These should be a 3D tensor with shape
<code class="docutils literal"><span class="pre">(num_filters,</span> <span class="pre">num_input_channels,</span> <span class="pre">filter_length)</span></code>.
See <code class="xref py py-func docutils literal"><span class="pre">lasagne.utils.create_param()</span></code> for more information.</p>
</div></blockquote>
<p><strong>b</strong> : Theano shared variable, expression, numpy array, callable or <code class="docutils literal"><span class="pre">None</span></code></p>
<blockquote>
<div><p>Initial value, expression or initializer for the biases. If set to
<code class="docutils literal"><span class="pre">None</span></code>, the layer will have no biases. Otherwise, biases should be
a 1D array with shape <code class="docutils literal"><span class="pre">(num_filters,)</span></code> if <cite>untied_biases</cite> is set to
<code class="docutils literal"><span class="pre">False</span></code>. If it is set to <code class="docutils literal"><span class="pre">True</span></code>, its shape should be
<code class="docutils literal"><span class="pre">(num_filters,</span> <span class="pre">input_length)</span></code> instead.
See <code class="xref py py-func docutils literal"><span class="pre">lasagne.utils.create_param()</span></code> for more information.</p>
</div></blockquote>
<p><strong>nonlinearity</strong> : callable or None</p>
<blockquote>
<div><p>The nonlinearity that is applied to the layer activations. If None
is provided, the layer will be linear.</p>
</div></blockquote>
<p><strong>convolution</strong> : callable</p>
<blockquote>
<div><p>The convolution implementation to use. The
<cite>lasagne.theano_extensions.conv</cite> module provides some alternative
implementations for 1D convolutions, because the Theano API only
features a 2D convolution implementation. Usually it should be fine
to leave this at the default value.</p>
</div></blockquote>
<p><strong>**kwargs</strong></p>
<blockquote class="last">
<div><p>Any additional keyword arguments are passed to the <cite>Layer</cite> superclass.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>Theano&#8217;s underlying convolution (<code class="xref py py-func docutils literal"><span class="pre">theano.tensor.nnet.conv.conv2d()</span></code>)
only supports <code class="docutils literal"><span class="pre">pad=0</span></code> and <code class="docutils literal"><span class="pre">pad='full'</span></code>. This layer emulates other modes
by cropping a full convolution or explicitly padding the input with zeros.</p>
<p class="rubric">Attributes</p>
<table border="1" class="docutils">
<colgroup>
<col width="3%" />
<col width="97%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>W</td>
<td>(Theano shared variable or expression) Variable or expression representing the filter weights.</td>
</tr>
<tr class="row-even"><td>b</td>
<td>(Theano shared variable or expression) Variable or expression representing the biases.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="clip2frame.layers.GaussianScan1DLayer.get_W_shape">
<code class="descname">get_W_shape</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/clip2frame/layers.html#GaussianScan1DLayer.get_W_shape"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#clip2frame.layers.GaussianScan1DLayer.get_W_shape" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the shape of the weight matrix <cite>W</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">tuple of int</p>
<blockquote class="last">
<div><p>The shape of the weight matrix.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="clip2frame.layers.MaxPool2DXLayer">
<em class="property">class </em><code class="descclassname">clip2frame.layers.</code><code class="descname">MaxPool2DXLayer</code><span class="sig-paren">(</span><em>incoming</em>, <em>pool_size</em>, <em>stride=None</em>, <em>pad=(0</em>, <em>0)</em>, <em>ignore_border=True</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/clip2frame/layers.html#MaxPool2DXLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#clip2frame.layers.MaxPool2DXLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>2D max-pooling layer</p>
<p>Performs 2D max-pooling over the two trailing axes of a 4D input tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>incoming</strong> : a <code class="xref py py-class docutils literal"><span class="pre">Layer</span></code> instance or tuple</p>
<blockquote>
<div><p>The layer feeding into this layer, or the expected input shape.</p>
</div></blockquote>
<p><strong>pool_size</strong> : integer or iterable</p>
<blockquote>
<div><p>The length of the pooling region in each dimension.  If an integer, it
is promoted to a square pooling region. If an iterable, it should have
two elements.</p>
</div></blockquote>
<p><strong>stride</strong> : integer, iterable or <code class="docutils literal"><span class="pre">None</span></code></p>
<blockquote>
<div><p>The strides between sucessive pooling regions in each dimension.
If <code class="docutils literal"><span class="pre">None</span></code> then <code class="docutils literal"><span class="pre">stride</span> <span class="pre">=</span> <span class="pre">pool_size</span></code>.</p>
</div></blockquote>
<p><strong>pad</strong> : integer or iterable</p>
<blockquote>
<div><p>Number of elements to be added on each side of the input
in each dimension. Each value must be less than
the corresponding stride.</p>
</div></blockquote>
<p><strong>ignore_border</strong> : bool</p>
<blockquote>
<div><p>If <code class="docutils literal"><span class="pre">True</span></code>, partial pooling regions will be ignored.
Must be <code class="docutils literal"><span class="pre">True</span></code> if <code class="docutils literal"><span class="pre">pad</span> <span class="pre">!=</span> <span class="pre">(0,</span> <span class="pre">0)</span></code>.</p>
</div></blockquote>
<p><strong>**kwargs</strong></p>
<blockquote class="last">
<div><p>Any additional keyword arguments are passed to the <code class="xref py py-class docutils literal"><span class="pre">Layer</span></code>
superclass.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>The value used to pad the input is chosen to be less than
the minimum of the input, so that the output of each pooling region
always corresponds to some element in the unpadded input region.</p>
<p>Using <code class="docutils literal"><span class="pre">ignore_border=False</span></code> prevents Theano from using cuDNN for the
operation, so it will fall back to a slower implementation.</p>
</dd></dl>

<dl class="class">
<dt id="clip2frame.layers.Pool2DXLayer">
<em class="property">class </em><code class="descclassname">clip2frame.layers.</code><code class="descname">Pool2DXLayer</code><span class="sig-paren">(</span><em>incoming</em>, <em>pool_size</em>, <em>stride=None</em>, <em>pad=(0</em>, <em>0)</em>, <em>ignore_border=True</em>, <em>mode='max'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/clip2frame/layers.html#Pool2DXLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#clip2frame.layers.Pool2DXLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>2D pooling layer</p>
<p>Performs 2D mean or max-pooling over the two trailing axes
of a 4D input tensor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>incoming</strong> : a <code class="xref py py-class docutils literal"><span class="pre">Layer</span></code> instance or tuple</p>
<blockquote>
<div><p>The layer feeding into this layer, or the expected input shape.</p>
</div></blockquote>
<p><strong>pool_size</strong> : integer or iterable</p>
<blockquote>
<div><p>The length of the pooling region in each dimension.  If an integer, it
is promoted to a square pooling region. If an iterable, it should have
two elements.</p>
</div></blockquote>
<p><strong>stride</strong> : integer, iterable or <code class="docutils literal"><span class="pre">None</span></code></p>
<blockquote>
<div><p>The strides between sucessive pooling regions in each dimension.
If <code class="docutils literal"><span class="pre">None</span></code> then <code class="docutils literal"><span class="pre">stride</span> <span class="pre">=</span> <span class="pre">pool_size</span></code>.</p>
</div></blockquote>
<p><strong>pad</strong> : integer or iterable</p>
<blockquote>
<div><p>Number of elements to be added on each side of the input
in each dimension. Each value must be less than
the corresponding stride.</p>
</div></blockquote>
<p><strong>ignore_border</strong> : bool</p>
<blockquote>
<div><p>If <code class="docutils literal"><span class="pre">True</span></code>, partial pooling regions will be ignored.
Must be <code class="docutils literal"><span class="pre">True</span></code> if <code class="docutils literal"><span class="pre">pad</span> <span class="pre">!=</span> <span class="pre">(0,</span> <span class="pre">0)</span></code>.</p>
</div></blockquote>
<p><strong>mode</strong> : {&#8216;max&#8217;, &#8216;average_inc_pad&#8217;, &#8216;average_exc_pad&#8217;}</p>
<blockquote>
<div><p>Pooling mode: max-pooling or mean-pooling including/excluding zeros
from partially padded pooling regions. Default is &#8216;max&#8217;.</p>
</div></blockquote>
<p><strong>**kwargs</strong></p>
<blockquote class="last">
<div><p>Any additional keyword arguments are passed to the <code class="xref py py-class docutils literal"><span class="pre">Layer</span></code>
superclass.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<dl class="last docutils">
<dt><code class="xref py py-obj docutils literal"><span class="pre">MaxPool2DLayer</span></code></dt>
<dd>Shortcut for max pooling layer.</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>The value used to pad the input is chosen to be less than
the minimum of the input, so that the output of each pooling region
always corresponds to some element in the unpadded input region.</p>
<p>Using <code class="docutils literal"><span class="pre">ignore_border=False</span></code> prevents Theano from using cuDNN for the
operation, so it will fall back to a slower implementation.</p>
</dd></dl>

<dl class="function">
<dt id="clip2frame.layers.conv1d_mc0">
<code class="descclassname">clip2frame.layers.</code><code class="descname">conv1d_mc0</code><span class="sig-paren">(</span><em>input</em>, <em>filters</em>, <em>input_shape=None</em>, <em>filter_shape=None</em>, <em>border_mode='valid'</em>, <em>subsample=(1</em>, <em>)</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/clip2frame/layers.html#conv1d_mc0"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#clip2frame.layers.conv1d_mc0" title="Permalink to this definition">¶</a></dt>
<dd><p>using conv2d with width == 1</p>
</dd></dl>

<dl class="function">
<dt id="clip2frame.layers.conv_output_length">
<code class="descclassname">clip2frame.layers.</code><code class="descname">conv_output_length</code><span class="sig-paren">(</span><em>input_length</em>, <em>filter_size</em>, <em>stride</em>, <em>pad=0</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/clip2frame/layers.html#conv_output_length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#clip2frame.layers.conv_output_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper function to compute the output size of a convolution operation</p>
<p>This function computes the length along a single axis, which corresponds
to a 1D convolution. It can also be used for convolutions with higher
dimensionalities by using it individually for each axis.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>input_length</strong> : int</p>
<blockquote>
<div><p>The size of the input.</p>
</div></blockquote>
<p><strong>filter_size</strong> : int</p>
<blockquote>
<div><p>The size of the filter.</p>
</div></blockquote>
<p><strong>stride</strong> : int</p>
<blockquote>
<div><p>The stride of the convolution operation.</p>
</div></blockquote>
<p><strong>pad</strong> : int, &#8216;full&#8217; or &#8216;same&#8217; (default: 0)</p>
<blockquote>
<div><p>By default, the convolution is only computed where the input and the
filter fully overlap (a valid convolution). When <code class="docutils literal"><span class="pre">stride=1</span></code>, this
yields an output that is smaller than the input by <code class="docutils literal"><span class="pre">filter_size</span> <span class="pre">-</span> <span class="pre">1</span></code>.
The <cite>pad</cite> argument allows you to implicitly pad the input with zeros,
extending the output size.</p>
<p>A single integer results in symmetric zero-padding of the given size on
both borders.</p>
<p><code class="docutils literal"><span class="pre">'full'</span></code> pads with one less than the filter size on both sides. This
is equivalent to computing the convolution wherever the input and the
filter overlap by at least one position.</p>
<p><code class="docutils literal"><span class="pre">'same'</span></code> pads with half the filter size on both sides (one less on
the second side for an even filter size). When <code class="docutils literal"><span class="pre">stride=1</span></code>, this
results in an output size equal to the input size.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">int</p>
<blockquote>
<div><p>The output size corresponding to the given convolution parameters.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Raises:</th><td class="field-body"><p class="first"><strong>RuntimeError</strong></p>
<blockquote class="last">
<div><p>When an invalid padding is specified, a <cite>RuntimeError</cite> is raised.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="clip2frame.layers.pool_output_length">
<code class="descclassname">clip2frame.layers.</code><code class="descname">pool_output_length</code><span class="sig-paren">(</span><em>input_length</em>, <em>pool_size</em>, <em>stride</em>, <em>pad</em>, <em>ignore_border</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/clip2frame/layers.html#pool_output_length"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#clip2frame.layers.pool_output_length" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the output length of a pooling operator
along a single dimension.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>input_length</strong> : integer</p>
<blockquote>
<div><p>The length of the input in the pooling dimension</p>
</div></blockquote>
<p><strong>pool_size</strong> : integer</p>
<blockquote>
<div><p>The length of the pooling region</p>
</div></blockquote>
<p><strong>stride</strong> : integer</p>
<blockquote>
<div><p>The stride between successive pooling regions</p>
</div></blockquote>
<p><strong>pad</strong> : integer</p>
<blockquote>
<div><p>The number of elements to be added to the input on each side.</p>
</div></blockquote>
<p><strong>ignore_border: bool</strong></p>
<blockquote>
<div><p>If <code class="docutils literal"><span class="pre">True</span></code>, partial pooling regions will be ignored.
Must be <code class="docutils literal"><span class="pre">True</span></code> if <code class="docutils literal"><span class="pre">pad</span> <span class="pre">!=</span> <span class="pre">0</span></code>.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">output_length</p>
<blockquote class="last">
<div><ul class="simple">
<li>None if either input is None.</li>
<li>Computed length of the pooling operator otherwise.</li>
</ul>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>When <code class="docutils literal"><span class="pre">ignore_border</span> <span class="pre">==</span> <span class="pre">True</span></code>, this is given by the number of full
pooling regions that fit in the padded input length,
divided by the stride (rounding down).</p>
<p>If <code class="docutils literal"><span class="pre">ignore_border</span> <span class="pre">==</span> <span class="pre">False</span></code>, a single partial pooling region is
appended if at least one input element would be left uncovered otherwise.</p>
</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="descclassname">clip2frame.layers.</code><code class="descname">GaussianScan1DLayer</code><span class="sig-paren">(</span><em>incoming</em>, <em>filter_size</em>, <em>init_std</em>, <em>stride=1</em>, <em>pad=0</em>, <em>untie_biases=False</em>, <em>W=lasagne.init.GlorotUniform()</em>, <em>b=lasagne.init.Constant(0.)</em>, <em>nonlinearity=lasagne.nonlinearities.rectify</em>, <em>convolution=lasagne.theano_extensions.conv.conv1d_mc0</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/clip2frame/layers.html#GaussianScan1DLayer"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>1D convolutional layer</p>
<p>Performs a 1D convolution on its input and optionally adds a bias and
applies an elementwise nonlinearity.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>incoming</strong> : a <code class="xref py py-class docutils literal"><span class="pre">Layer</span></code> instance or a tuple</p>
<blockquote>
<div><p>The layer feeding into this layer, or the expected input shape. The
output of this layer should be a 3D tensor, with shape
<code class="docutils literal"><span class="pre">(batch_size,</span> <span class="pre">num_input_channels,</span> <span class="pre">input_length)</span></code>.</p>
</div></blockquote>
<p><strong>num_filters</strong> : int</p>
<blockquote>
<div><p>The number of learnable convolutional filters this layer has.</p>
</div></blockquote>
<p><strong>filter_size</strong> : int or iterable of int</p>
<blockquote>
<div><p>An integer or a 1-element tuple specifying the size of the filters.</p>
</div></blockquote>
<p><strong>stride</strong> : int or iterable of int</p>
<blockquote>
<div><p>An integer or a 1-element tuple specifying the stride of the
convolution operation.</p>
</div></blockquote>
<p><strong>pad</strong> : int, iterable of int, &#8216;full&#8217;, &#8216;same&#8217; or &#8216;valid&#8217; (default: 0)</p>
<blockquote>
<div><p>By default, the convolution is only computed where the input and the
filter fully overlap (a valid convolution). When <code class="docutils literal"><span class="pre">stride=1</span></code>, this
yields an output that is smaller than the input by <code class="docutils literal"><span class="pre">filter_size</span> <span class="pre">-</span> <span class="pre">1</span></code>.
The <cite>pad</cite> argument allows you to implicitly pad the input with zeros,
extending the output size.</p>
<p>An integer or a 1-element tuple results in symmetric zero-padding of
the given size on both borders.</p>
<p><code class="docutils literal"><span class="pre">'full'</span></code> pads with one less than the filter size on both sides. This
is equivalent to computing the convolution wherever the input and the
filter overlap by at least one position.</p>
<p><code class="docutils literal"><span class="pre">'same'</span></code> pads with half the filter size (rounded down) on both sides.
When <code class="docutils literal"><span class="pre">stride=1</span></code> this results in an output size equal to the input
size. Even filter size is not supported.</p>
<p><code class="docutils literal"><span class="pre">'valid'</span></code> is an alias for <code class="docutils literal"><span class="pre">0</span></code> (no padding / a valid convolution).</p>
</div></blockquote>
<p><strong>untie_biases</strong> : bool (default: False)</p>
<blockquote>
<div><p>If <code class="docutils literal"><span class="pre">False</span></code>, the layer will have a bias parameter for each channel,
which is shared across all positions in this channel. As a result, the
<cite>b</cite> attribute will be a vector (1D).</p>
<p>If True, the layer will have separate bias parameters for each
position in each channel. As a result, the <cite>b</cite> attribute will be a
matrix (2D).</p>
</div></blockquote>
<p><strong>W</strong> : Theano shared variable, expression, numpy array or callable</p>
<blockquote>
<div><p>Initial value, expression or initializer for the weights.
These should be a 3D tensor with shape
<code class="docutils literal"><span class="pre">(num_filters,</span> <span class="pre">num_input_channels,</span> <span class="pre">filter_length)</span></code>.
See <code class="xref py py-func docutils literal"><span class="pre">lasagne.utils.create_param()</span></code> for more information.</p>
</div></blockquote>
<p><strong>b</strong> : Theano shared variable, expression, numpy array, callable or <code class="docutils literal"><span class="pre">None</span></code></p>
<blockquote>
<div><p>Initial value, expression or initializer for the biases. If set to
<code class="docutils literal"><span class="pre">None</span></code>, the layer will have no biases. Otherwise, biases should be
a 1D array with shape <code class="docutils literal"><span class="pre">(num_filters,)</span></code> if <cite>untied_biases</cite> is set to
<code class="docutils literal"><span class="pre">False</span></code>. If it is set to <code class="docutils literal"><span class="pre">True</span></code>, its shape should be
<code class="docutils literal"><span class="pre">(num_filters,</span> <span class="pre">input_length)</span></code> instead.
See <code class="xref py py-func docutils literal"><span class="pre">lasagne.utils.create_param()</span></code> for more information.</p>
</div></blockquote>
<p><strong>nonlinearity</strong> : callable or None</p>
<blockquote>
<div><p>The nonlinearity that is applied to the layer activations. If None
is provided, the layer will be linear.</p>
</div></blockquote>
<p><strong>convolution</strong> : callable</p>
<blockquote>
<div><p>The convolution implementation to use. The
<cite>lasagne.theano_extensions.conv</cite> module provides some alternative
implementations for 1D convolutions, because the Theano API only
features a 2D convolution implementation. Usually it should be fine
to leave this at the default value.</p>
</div></blockquote>
<p><strong>**kwargs</strong></p>
<blockquote class="last">
<div><p>Any additional keyword arguments are passed to the <cite>Layer</cite> superclass.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>Theano&#8217;s underlying convolution (<code class="xref py py-func docutils literal"><span class="pre">theano.tensor.nnet.conv.conv2d()</span></code>)
only supports <code class="docutils literal"><span class="pre">pad=0</span></code> and <code class="docutils literal"><span class="pre">pad='full'</span></code>. This layer emulates other modes
by cropping a full convolution or explicitly padding the input with zeros.</p>
<p class="rubric">Attributes</p>
<table border="1" class="docutils">
<colgroup>
<col width="3%" />
<col width="97%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td>W</td>
<td>(Theano shared variable or expression) Variable or expression representing the filter weights.</td>
</tr>
<tr class="row-even"><td>b</td>
<td>(Theano shared variable or expression) Variable or expression representing the biases.</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt>
<code class="descname">get_W_shape</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/clip2frame/layers.html#GaussianScan1DLayer.get_W_shape"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Get the shape of the weight matrix <cite>W</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body"><p class="first">tuple of int</p>
<blockquote class="last">
<div><p>The shape of the weight matrix.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="../misc/data.html"
                        title="previous chapter">data/</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/modules/layers.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <div><input type="text" name="q" /></div>
      <div><input type="submit" value="Go" /></div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="../misc/data.html" title="data/"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">clip2frame 0.1.0 documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &copy; Copyright 2016, Jen-Yu Liu.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.4.5.
    </div>
  </body>
</html>